{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMI1xsZCy/qVPJt6dab8o5z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodewSanthosh/sdc-Gen-AI/blob/main/YoutubeSummmarizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIwV1xTe4Ta6",
        "outputId": "b5b33bc4-f98a-48e2-b8e8-cbca7f4cefcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching transcript...\n",
            "Summarizing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Your max_length is set to 150, but your input_length is only 78. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=39)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== YouTube Video Summary ===\n",
            "\n",
            "\"I have lots of different designs slashprompts which you can utilize yourself and use however you want now this is my public profile as I just stated and what I'll do is also link this down in the description so you can come through check it out and use whatever you want\" \"The further you go down this list the more cool stuff you're going to find\" \"I wanted to come up with a way that you could utilize all of these prompts here on my public profile and generate an endless amount of new prompts\" \"So what I've gone ahead and done is created a completely free little miniourse now this is called Prompt Playground and what I'll do is also link this down in the description now this says it's not currently available\" Once in Gumroad you'll have access to this so I'll just quickly cover all the modules there's a welcome and overview module then a module all about my public profile then there's the one about t-shirt prompts sticker prompts clip art prompts coloring page prompts and then a little thank you video as well. Coloring pages can be turned into t-shirt designs, stickers and or clip art. This video includes some of the best ideas I've ever seen for coloring pages. If you found this video helpful at all then please consider giving me a like.\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install youtube-transcript-api transformers sentencepiece --quiet\n",
        "\n",
        "# Import libraries\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from transformers import pipeline\n",
        "import re\n",
        "\n",
        "# Extract Video ID from URL\n",
        "def get_video_id(url):\n",
        "    match = re.search(r'(?:v=|\\/)([0-9A-Za-z_-]{11}).*', url)\n",
        "    return match.group(1) if match else None\n",
        "\n",
        "# Fetch YouTube Transcript\n",
        "def fetch_transcript(video_url):\n",
        "    video_id = get_video_id(video_url)\n",
        "    if not video_id:\n",
        "        raise ValueError(\"Invalid YouTube URL.\")\n",
        "    transcript_data = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "    transcript = \" \".join([entry['text'] for entry in transcript_data])\n",
        "    return transcript\n",
        "\n",
        "# Summarize Text using Hugging Face Model\n",
        "def summarize_text(text, max_chunk=1000):\n",
        "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "    # Split text into manageable chunks\n",
        "    chunks = [text[i:i + max_chunk] for i in range(0, len(text), max_chunk)]\n",
        "    summaries = []\n",
        "\n",
        "    for chunk in chunks:\n",
        "        summary = summarizer(chunk, max_length=150, min_length=40, do_sample=False)[0]['summary_text']\n",
        "        summaries.append(summary)\n",
        "\n",
        "    return \" \".join(summaries)\n",
        "\n",
        "# Main Flow\n",
        "video_url = \"https://youtu.be/gFmD43W0Hi0?si=xHxDhGUbRuWGC8UF\"  # Replace with your video URL\n",
        "\n",
        "try:\n",
        "    print(\"Fetching transcript...\")\n",
        "    transcript = fetch_transcript(video_url)\n",
        "\n",
        "    print(\"Summarizing...\")\n",
        "    final_summary = summarize_text(transcript)\n",
        "\n",
        "    print(\"\\n=== YouTube Video Summary ===\\n\")\n",
        "    print(final_summary)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Error:\", str(e))\n"
      ]
    }
  ]
}